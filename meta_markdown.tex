\documentclass[man]{apa6}

\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
    \usepackage{xltxtra,xunicode}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Mapping=tex-text,Scale=MatchLowercase}
  \newcommand{\euro}{€}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{\usepackage{microtype}}{}

% Table formatting
\usepackage{longtable, booktabs}
\usepackage{lscape}
% \usepackage[counterclockwise]{rotating}   % Landscape page setup for large tables
\usepackage{multirow}		% Table styling
\usepackage{tabularx}		% Control Column width
\usepackage[flushleft]{threeparttable}	% Allows for three part tables with a specified notes section
\usepackage{threeparttablex}            % Lets threeparttable work with longtable

% Create new environments so endfloat can handle them
% \newenvironment{ltable}
%   {\begin{landscape}\begin{center}\begin{threeparttable}}
%   {\end{threeparttable}\end{center}\end{landscape}}

\newenvironment{lltable}
  {\begin{landscape}\begin{center}\begin{ThreePartTable}}
  {\end{ThreePartTable}\end{center}\end{landscape}}

  \usepackage{ifthen} % Only add declarations when endfloat package is loaded
  \ifthenelse{\equal{\string man}{\string man}}{%
   \DeclareDelayedFloatFlavor{ThreePartTable}{table} % Make endfloat play with longtable
   % \DeclareDelayedFloatFlavor{ltable}{table} % Make endfloat play with lscape
   \DeclareDelayedFloatFlavor{lltable}{table} % Make endfloat play with lscape & longtable
  }{}%



% The following enables adjusting longtable caption width to table width
% Solution found at http://golatex.de/longtable-mit-caption-so-breit-wie-die-tabelle-t15767.html
\makeatletter
\newcommand\LastLTentrywidth{1em}
\newlength\longtablewidth
\setlength{\longtablewidth}{1in}
\newcommand\getlongtablewidth{%
 \begingroup
  \ifcsname LT@\roman{LT@tables}\endcsname
  \global\longtablewidth=0pt
  \renewcommand\LT@entry[2]{\global\advance\longtablewidth by ##2\relax\gdef\LastLTentrywidth{##2}}%
  \@nameuse{LT@\roman{LT@tables}}%
  \fi
\endgroup}


  \usepackage{graphicx}
  \makeatletter
  \def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
  \def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
  \makeatother
  % Scale images if necessary, so that they will not overflow the page
  % margins by default, and it is still possible to overwrite the defaults
  % using explicit options in \includegraphics[width, height, ...]{}
  \setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\ifxetex
  \usepackage[setpagesize=false, % page size defined by xetex
              unicode=false, % unicode breaks when used with xetex
              xetex]{hyperref}
\else
  \usepackage[unicode=true]{hyperref}
\fi
\hypersetup{breaklinks=true,
            pdfauthor={},
            pdftitle={A Meta-Analysis of Expressive Writing on Posttraumatic Stress, Posttraumatic Growth, and Quality of Life},
            colorlinks=true,
            citecolor=blue,
            urlcolor=blue,
            linkcolor=black,
            pdfborder={0 0 0}}
\urlstyle{same}  % don't use monospace font for urls

\setlength{\parindent}{0pt}
%\setlength{\parskip}{0pt plus 0pt minus 0pt}

\setlength{\emergencystretch}{3em}  % prevent overfull lines


% Manuscript styling
\captionsetup{font=singlespacing,justification=justified}
\usepackage{csquotes}
\usepackage{upgreek}

 % Line numbering
  \usepackage{lineno}
  \linenumbers


\usepackage{tikz} % Variable definition to generate author note

% fix for \tightlist problem in pandoc 1.14
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}

% Essential manuscript parts
  \title{A Meta-Analysis of Expressive Writing on Posttraumatic Stress,
Posttraumatic Growth, and Quality of Life}

  \shorttitle{Expressive Writing}


  \author{Jeffrey M. Pavlacic\textsuperscript{1}, Erin M. Buchanan\textsuperscript{2}, Nicholas P. Maxwell\textsuperscript{2}, Tabetha G. Hopke\textsuperscript{2}, \& Stefan E. Schulenberg\textsuperscript{1}}

  \def\affdep{{"", "", "", "", ""}}%
  \def\affcity{{"", "", "", "", ""}}%

  \affiliation{
    \vspace{0.5cm}
          \textsuperscript{1} University of Mississippi\\
          \textsuperscript{2} Missouri State University  }

  \authornote{
    \newcounter{author}
    Jeffrey M. Pavlacic is a doctoral candidate at the University of
    Mississippi and a member of the University of Mississippi
    Clinical-Disaster Research Center (UM-CDRC). Erin M. Buchanan is an
    Associate Professor of Psychology at Missouri State University. Nicholas
    P. Maxwell completed his master's degree from Missouri State University
    and is a Ph.D.~candidate at the University of Southern Mississippi.
    Tabetha G. Hopke is a master's degree candidates at Missouri State
    University. Stefan E. Schulenberg is a Professor of Psychology at the
    University of Mississippi and director of the UM-CDRC.

                      Correspondence concerning this article should be addressed to Jeffrey M. Pavlacic, 205 Peabody Hall, University, MS 38655. E-mail: \href{mailto:jpavlaci@go.olemiss.edu}{\nolinkurl{jpavlaci@go.olemiss.edu}}
                                                        }


  \abstract{Expressive writing is beneficial for promoting both positive
psychological and physical health outcomes. Unfortunately, inhibiting
emotions is related to impairments in psychological and physical health.
James Pennebaker and others have used expressive writing as an
experimental manipulation to gauge its efficacy in treating a wide
variety of physical and psychological outcomes. While many studies have
been conducted that examine the efficacy of expressive writing across
such outcomes, a considerable amount of these studies tend to neglect
necessary considerations such as different levels of symptomatology,
power, and meaningfulness of respective effect sizes. Six previous
meta-analyses have been conducted that examine expressive writing's
effect on psychological outcomes. However, these studies focus on the
experimental versus control group effect size. Thus, our meta-analysis
sought to examine the efficacy of an expressive writing task on only the
experimental conditions in studies measuring posttraumatic stress,
posttraumatic growth, and quality of life using random effects models.
Results indicated a small overall effect size for posttraumatic stress
and negligible to small effect sizes for posttraumatic growth and
quality of life. However, those studies requiring a diagnosis of PTSD
exhibited a medium to large effect size. Implications for future
research design and interpretation of published research are discussed.}
  \keywords{meta-analysis, posttraumatic stress, posttraumatic growth, quality of
life, expressive writing \\

    
  }





\usepackage{amsthm}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\theoremstyle{definition}
\newtheorem{definition}{Definition}
\newtheorem{corollary}{Corollary}
\newtheorem{proposition}{Proposition}
\theoremstyle{definition}
\newtheorem{example}{Example}
\theoremstyle{definition}
\newtheorem{exercise}{Exercise}
\theoremstyle{remark}
\newtheorem*{remark}{Remark}
\newtheorem*{solution}{Solution}
\begin{document}

\maketitle

\setcounter{secnumdepth}{0}



\subsection{Expressive Writing}\label{expressive-writing}

Expressive writing enhances both physical and psychological outcomes
(Esterling, Antoni, Kumar, \& Schneiderman, 1990; Fawzy et al., 1993;
Lieberman \& Goldstein, 2006; Rachman, 1980; Scheff, 1979). Pennebaker
\& Beall (1986) first pioneered expressive writing, which involved
writing about the thoughts and feelings associated with either a
\enquote{stressful or traumatic} or neutral event. Further, the original
protocol included 3-5 writing sessions, each lasting 15-20 minutes in
length. In their seminal study employing expressive writing methodology
in comparison to a control group, Pennebaker \& Beall (1986) discovered
that participants assigned to write about thoughts and feelings related
to the stressful/traumatic event reported a reduction in health visits
at the university health center. Termed written emotional disclosure
(WED), this protocol has since been employed across varying contexts.
Indeed, as of 2014, the expressive writing literature recognizes over
400 studies across different populations and outcome variables (Niles,
Haltom, Mulvenna, Lieberman, \& Stanton, 2014). For example, WED is
efficacious for physical outcomes, such as reduced doctor visits for
those diagnosed with Type I diabetes (Bodor, 2002) or breast cancer
(Stanton et al., 2002) and medication use in those suffering from
chronic illness (i.e., asthma and rheumatoid arthritis; Smyth, Stone,
Hurewitz, \& Kaell, 1999). In regards to psychological outcomes, WED is
efficacious for reducing depression symptoms (Gortner, Rude, \&
Pennebaker, 2006), posttraumatic stress (Di Blasio et al., 2015), and
anxiety (Dean, Potts, \& Barker, 2016). Although expressive writing is
efficacious in producing favorable outcomes, avoiding thoughts or
physiological sensations releveant to a given emotion is problematic
across the aforementioned outcomes and contexts.

Individuals having experienced a traumatic or stressful life event are
more likely to avoid thoughts and feelings about their experience
compared to individuals who have not experienced such events, thereby
subjecting them to potential negative outcomes (Bodor, 2002). For
example, Posttraumatic Stress Disorder (PTSD) diagnostic criteria are
characterized by repeated attempts to cognitively or behaviorally avoid
thoughts, feelings, or places related to a given trauma (American
Psychiatric Association, 2013). Trauma patients who avoid intrusive
thoughts or physiological sensations experience various forms of
psychopathology, such as depression and trauma-related symptoms (Marx \&
Sloan, 2005), anxiety (Levitt, Brown, Orsillo, \& Barlow, 2004),
substance use (García-Oliva \& Piqueras, 2016), and social concerns
(Pennebaker, 1989; Pennebaker \& Beall, 1986). Although one proposed
mechanism of change is the hypothesis that expressive writing
interventions target the inhibition of thoughts and physiological
sensations via imaginal exposure, there are other proposed mechanisms
that may explain the efficacy of expressive writing (e.g., social
integration model, distance perspective; Kross \& Ayduk, 2011;
Pennebaker \& Graybeal, 2001). Although studies employing expressive
writing have produced positive psychological and physical outcomes, some
of these studies neglect necessary considerations, the most important of
which is whether or not the effects are meaningful (Smyth, 1998). For a
more in-depth review of the efficacy of WED across contexts, the authors
turn to previously-conducted meta-analyses.

\subsection{Meta-Analytic Techniques}\label{meta-analytic-techniques}

Meta-analyses allow researchers the opportunity to collectively examine
the efficacy of different psychological interventions/tasks on outcome
variables by calculating an overall, weighted, population effect
(Borenstein, Hedges, \& Rothstein, 2007; Glass, 1976; Hedges, 1982). The
following meta-analyses delineate the efficacy of expressive writing
across outcomes and warrant individual explanation: Smyth (1998);
Frisina, Borod, \& Lepore (2004); Frattaroli (2006); Mogk, Otte,
Reinhold-Hurley, \& Kröner-Herwig (2006); Van Emmerik, Reijntjes, \&
Kamphuis (2013); and Reinhold, Bürkner, \& Holling (2018).

Smyth (1998) conducted the seminal meta-analysis examining the efficacy
of expressive writing on psychological well-being, general health, and
physical functioning. They included studies employing an expressive
writing group and control group (i.e., neutral topic). In sum, 13
studies/effect sizes were included, and the authors found an overall
medium effect size, \emph{d} = 0.47, for the experimental group compared
to the control group. A later meta-analysis conducted by Frisina et al.
(2004) expanded these analyses and included studies with clinical
samples. This meta-analysis included nine studies and found an effect
size of \emph{d} = 0.19 for physical outcomes and \emph{d} = 0.07 for
psychological outcomes. Mogk et al. (2006) conducted the next expressive
writing meta-analysis to update the state of the literature regarding
expressive writing. Studies employing Pennebaker's paradigm on
experimental and control groups were included. Further, inclusion
criteria were methodological techniques that included a four-week follow
up and at least 10 participants. Thirty studies met inclusion criteria.
Efficacy relating to somatic and psychological health outcomes were
nonsignificant, corroborating findings from Frisina et al. (2004).

Frattaroli (2006) conducted perhaps the most notable meta-analysis to
date examining the efficacy of emotional disclosure on the following
constructs using only randomized and control conditions: psychological
health, physiological functioning, reported health, health behaviors,
and general functioning/life outcomes. Additionally, this meta-analysis
was the first to employ random effects models, which estimate the mean
of a proposed distribution of population effect sizes. Prior
meta-analyses employed fixed effects models, which assume that all
studies assess the same \enquote{true} population effect size. This
assumption may be untenable across different populations (Borenstein et
al., 2007). They included a wide range of studies, \emph{N} = 146.
Individual studies were again collapsed into one publication effect
size, although these effects were also examined separately by health
outcome. Overall, Frattaroli (2006) found \emph{d} = 0.16 for all
outcomes combined, which would be considered small. Additionally, they
examined potential moderators and found larger effect sizes for the
following samples: those with physical health problems, those with a
history of having experienced traumatic or stressful events, samples not
including college students, samples where expressive writing tasks were
conducted at home and in private settings, paid participants, more male
participants, and fewer participants (see Frattaroli, 2006 for a
complete list of moderators). A recent analysis conducted by Van Emmerik
et al. (2013) employing Pennebaker's paradigm included six eligible
studies that compared treatment to control groups. In regards to
inclusion criteria, they included studies where participants had a
diagnosis of Acute Stress Disorder or PTSD. They found that those who
participated in the expressive writing group experienced short-term
reductions in PTS and comorbid depressive symptoms, combined \emph{d} =
0.81.

The most recently published meta-analysis was conducted by Reinhold et
al. (2018) and examined the efficacy of expressive writing on depression
by randomizing participants to conditions (expressive writing
vs.~control). They included 39 randomized controlled trials and excluded
individuals with diagnoses of PTSD. This study did not support utilizing
expressive writing for depression outcome measures for the specified
sample, \emph{d} = -0.09. Further, they found that expressive writing
did not yield any type of long-term effect on depression outcomes. In
sum, previous meta-analyses exhibit small to medium effect sizes for a
brief, innocuous intervention and therefore individuals having
experienced trauma have been shown to benefit from such interventions.

\subsection{Posttraumatic Stress}\label{posttraumatic-stress}

Posttraumatic Stress Disorder is a condition involving re-experiencing
thoughts or events after a trauma. This generates a context where
individuals are prone to affect-related deficiencies and maladaptive
behaviors (American Psychiatric Association, 2013). DSM-5 criteria are
based on 20 symptoms structured into four different subsets in those
having experienced a traumatic event. These subsets are as follows:
intrusion symptoms (i.e., re-experiencing), avoidance, negative
alterations in cognition and mood, and increased arousal (Crespo \&
Gomez, 2016). While the renewed DSM-5 criteria are now increasingly
utilized via structured clinical interviews, the current meta-analysis
considers studies using DSM-IV criteria. DSM-IV criteria are similar and
include the following: exposure to a traumatic event, intrusion,
avoidance, and increased arousal (American Psychiatric Association,
2013). The studies employed in the current meta-analysis are divided
according to these subsets (arousal, intrusion, and avoidance).
Posttraumatic Stress Disorder affects a wide variety of populations,
including sexual assault survivors (Klump, 2008), Iraq and Afghanistan
war veterans (Gentes et al., 2014), and those exposed to natural
disasters (Wang et al., 2000).

Research conducted on the efficacy of expressive writing on PTSD
symptoms presents intriguing results. Sloan, Marx, Epstein, \& Lexington
(2007) examined individuals with at least moderate PTSD symptom severity
and found that individuals assigned to an expressive writing condition
reported fewer PTSD and depression symptoms during follow up. Sloan,
Marx, \& Greenberg (2011) found that PTSD symptoms decreased after a
written emotional disclosure task, although this decrease was not
significantly different than a control group change. Di Blasio et al.
(2015) recruited women who had just given birth and assessed them a few
days after experiencing childbirth along with a three-month follow-up.
Results showed that women who had participated in the expressive writing
task had lower depression and posttraumatic stress symptoms than the
group assigned to a neutral writing condition. Additionally, regression
models showed that expressive writing was significantly linked to a
reduction of PTSD symptoms across different dimensional levels of
symptom severity. Only 20 of the 113 women recruited for this study
qualified for a diagnosis of PTSD, but those who reported mild
symptomatology responded better to the task than those meeting criteria
for PTSD. This limitation suggests that those with moderate distress
could perhaps benefit more from an expressive writing task than those
diagnosed with or meeting the qualifications for PTSD. It may also
explain the differences in results in comparing to Sloan et al. (2011),
as they found that those with a clinical diagnosis of PTSD did not
respond to an emotional disclosure writing task. Perhaps it may be more
advantageous to examine effect sizes separately for diagnoses of PTSD
and subclinical symptoms.

Sloan, Marx, Bovin, Feinstein, \& Gallagher (2012) adapted a writing
protocol to focus primarily on the emotions, meaning, and \enquote{hot
spots} associated with the trauma. They referred to this procedure as
the written exposure therapy (WET) protocol, distinguishable from the
paradigm adapted by Pennebaker \& Beall (1986). In their seminal study
examining the efficacy of WET for motor-vehicle accident related PTSD,
they found that those in the WET condition experienced significant
reductions in PTSD symptoms throughout the course of the study. Since
then, a small number of other studies employing the WET procedure have
been employed in those with PTSD. Indeed, Sloan, Marx, Lee, \& Resick
(2018) found that WET was noninferior (i.e., just as effective) as
Cognitive Processing Therapy, considered first-line treatment for PTSD.
Further, treatment gains were maintained at 24 and 36-week follow up.
While studies employing this protocol will be included in the current
review, the newness of this protocol does not allow exclusive
examination using meta-analytic techniques.

\subsection{Posttraumatic Growth}\label{posttraumatic-growth}

While the literature mostly discusses potentially harmful outcomes to
traumatic events such as emotional distress, traumatic events also
provide opportunities for personal growth (Aslam \& Kamal, 2013).
Traumatic events, either natural or human-inflicted, may lead to
positive outcomes by allowing the individual to take a different
perspective (Cobb, Tedeschi, Calhoun, \& Cann, 2006; Taku, Calhoun,
Cann, \& Tedeschi, 2008). The relationship between positive growth after
a traumatic event and symptom reduction is unclear, as it is a complex
process. Thus, it is necessary to examine how expressive writing might
influence each variable separately, which is one of the key goals of
this meta-analysis (Slavin-Spenny, Cohen, Oberleitner, \& Lumley, 2011).
Models receiving empirical support within the last decade suggest that
traumatic events offer opportunities for both negative and positive
experiences (Tedeschi \& Calhoun, 1995; Weiss, 2002). Posttraumatic
Growth (PTG) is a positive experience after a traumatic event (Aslam \&
Kamal, 2013; Yilmaz \& Zara, 2016). Specifically, PTG is classified as
broad cognitive benefits that are seen after a traumatic experience.
These benefits can be categorized into building closer relationships,
examining new possibilities, appreciating life, recognizing personal
strengths, and undergoing spiritual changes (Dursun, Steger, Bentele, \&
Schulenberg, 2016; Tedeschi \& Calhoun, 2004). ({\textbf{???}}) further
suggest that traumatic experiences disrupt one's core beliefs, thereby
leading to emotional or cognitive difficulties (e.g., rumination). Given
the wide range hypotheses on the underlying mechanisms (i.e., cognitive
and emotional), perhaps expressive writing serves as a way for
individuals to process the emotions related to the trauma via
higher-order cognitive processes or imaginal exposure. For this reason,
the current meta-analysis sought to test whether expressive writing has
any effect on PTG.

PTG is associated with a variety of desired outcomes (Dursun et al.,
2016). PTG has been studied in those experiencing natural disasters,
war, and other harms such as sexual assault. Finally, PTG has been
studied in those experiencing medical diagnoses such as different types
of cancer and diseases. Although the relationship between PTG and
symptom reduction is not yet fully understood, perhaps expressive
writing allows the individual to fully comprehend the event. Pennebaker
\& Graybeal (2001) speculated that expressive writing allows an
individual to feel more connected with his or her surroundings. Although
this speculation does not directly explain positive outcomes after an
expressive writing task, perhaps individuals gain a better appreciation
for life after gaining a better sense of connectedness with that
individual's surroundings. One might expect effect sizes to be larger
for those studies requiring a diagnosis of PTSD, as such growth may not
be possible in those with subclinical symptomatology.

\subsection{Quality of Life}\label{quality-of-life}

Quality of Life (QOL), according to Theofilou (2013) is an evaluation of
the \enquote{goodness} that an individual experiences, separated into
domains of reactions to life events, disposition, life fulfillment, and
satisfaction with life experiences. More generally, QOL refers to an
individual's attitude towards the target life situation (Costanza et
al., 2007), delineated into objective and subjective components.
Objectively, QOL refers to components outside of an individual and
measurable by others, while subjective QOL is an individual's assessment
of his or her own experiences (Costanza et al., 2007). The current
meta-analysis will focus solely on the subjective components of QOL, as
it is obtainable through questionnaires. Similar to the
conceptualization of PTG, Pennebaker \& Graybeal (2001) proposed that
engaging in expressive writing results in connectedness to the
environment. Further, they explain that expressive writing allows people
to see things in a different way and better understand themselves. By
understanding a traumatic or stressful event, one is said to see things
differently and perhaps look at the situation with a more positive
mindset. The changes that occur after expressive writing may also allow
one to find meaning in the traumatic event, thereby increasing the QOL
of that individual (Frankl, 1959). Higher QOL may be considered a type
of PTG, which is why the current meta-analysis sought to examine the
efficacy of studies utilizing expressive writing to improve QOL and PTG
in the same study.

\subsection{Current Meta-Analysis}\label{current-meta-analysis}

The purpose of the current meta-analysis is to examine studies employing
expressive writing procedures using Pennebaker's paradigm (WED) and the
more recent WET protocol on variables relevant to the field of positive
psychology (PTG and QOL) and PTS, with effect sizes separated by the
paper's indication of PTSD diagnosis when sample sizes are large enough.
Based on recently published literature regarding efficacy of expressive
writing for different levels of PTSD symptoms, this diagnostic marker is
an important facet to consider (Di Blasio et al., 2015; Reinhold et al.,
2018; Sloan et al., 2011). No review has examined the efficacy of
expressive writing on PTS separated by diagnosis. Additionally, no
meta-analysis has been conducted that examines the efficacy of
expressive writing on positive outcome variables such as PTG and QOL, in
line with the fields of positive psychology and psychology more
generally. The meta-analyses described sequentially above also focused
on experimental versus control group effect sizes or \emph{p}-values,
rather than emphasizing change for the expressive writing group. This
focus is likely because of the analyses provided in these publications,
especially when using randomized controlled trial research designs.
While this design is the gold standard for medicine, the current
meta-analysis sought to examine the magnitude of change for participants
who experienced an expressive writing task. For example, a comparison
group may increase their quality of life scores by two points in a
controlled study, while the experimental group increases their quality
of life scores by four points; thus, creating a significant difference
in change between the two groups. This information is valuable, but it
does not tell the reader the magnitude of the change for the writing
group, wherein four points might only be a small effect when examined
within the group who received the writing task.

This analysis will also focus on changes across time for groups who
received the expressive writing task to determine what size of effects
one might expect given a specific measurement schedule (i.e., one to
three months, three months to six months, etc.). Indeed, Sloan et al.
(2018) discovered long-term gains for those in the WET condition. This
analysis should present researchers with a renewed examination of the
efficacy of expressive writing on the aforementioned variables using
newer meta-analytic techniques. Newer methods of meta-analysis,
including \emph{p}-curve (Simonsohn, Nelson, \& Simmons, 2014;
Simonsohn, Simmons, \& Nelson, 2015), \emph{p}-uniform (Van Aert,
Wicherts, \& Van Assen, 2016), PET-PEESE (Stanley \& Doucouliagos,
2014), selection models (Vevea \& Hedges, 1995), and trim and fill
methods (Carter \& McCullough, 2014) allow for better estimation of
meta-analytic effect sizes. These analyses would be best performed by
examining each potential effect separately, rather than averaging
effects of each publication into one study effect size (a common trend
in the previously mentioned meta-analysis). In addition to an estimate
of overall effect sizes using updated techniques, the current
meta-analysis estimates power for effects on writing groups, as research
has shown a consistent under powering of psychological studies, combined
with a misunderstanding of the sample size needed for adequately
powering one's work (Bakker, Hartgerink, Wicherts, \& Van Der Maas,
2016).

\section{Method}\label{method}

\subsection{Data Collection}\label{data-collection}

Studies were collected through online databases, such as PsycINFO and
Google Scholar, using the following search terms and their combinations:
\emph{Posttraumatic Growth, PTG, Quality of Life, QOL, Posttraumatic
Stress, PTS, Expressive Writing, Emotional Disclosure, Written Emotional
Disclosure (WED), Written Exposure Therapy (WET)}. Within these
articles, the change in outcome variables (PTS, PTG, QOL) from pre- to
post-test was the dependent variable of interest. Generally, groups were
separated into an experimental and control group and then examined at
different time points. For purposes of this meta-analysis, only
participants assigned to the experimental condition were examined due to
having received the expressive writing task. If a study included
multiple assessment time points, then these measurements were examined
sequentially (i.e., time 1 to time 2, time 2 to time 3) to determine
change across time for the dependent variable. The time variable was
coded as the number of months between two comparison points. For
example, if a study included three time points (baseline, one month,
three months), two pairwise effect sizes would be calculated (baseline
to one month, one month to three months) and the time variable would be
one month for comparison one and two months for comparison two. If a
study included multiple experimental conditions (i.e., different
instructions or forms for WED), all experimental conditions were
included in the dataset.

264 citations focusing on PTS, PTG, and QOL were identified through the
literature search and previous meta-analyses. Citations for PTS were
separated by diagnostic criteria (intrusions, avoidance, and
hyperarousal), where possible. After screening these studies, 53
articles were retained for containing the appropriate information for
this meta-analysis. This manuscript was written with \emph{papaja} in
\emph{R} (Aust \& Barth, 2017) with the analyses inline with the text.
The complete set of data, excluded article list with reasoning, and
other relevant information can be found at: \url{https://osf.io/4mjqt}.
Generally, studies were included if they utilized WED or WET, included
relevant numbers to compute an effect size, and included the relevant
outcome variables. The questionnaire for each relevant outcome variable
is coded in the online data provided on the Open Science Framework (link
above). These varied across study, however, the nature of Cohen's
\emph{d} allows for different Likert-type scales, as it takes into
consideration the study standard deviation in the denominator to create
standardized scores for comparison across studies.

After having two reviewers independently code articles, 223 effect sizes
were calculated. On average, each study represented \emph{M} = 4.21,
\emph{SD} = 3.31 effects, ranging from 1 to 16 effects. 163 effects were
calculated for PTS, 21 for PTG, and 37 for QOL. Studies were coded for
PTSD diagnosis as no (not mentioned or not included), mixed (mentioned
number of participants but all included), and yes (included as
criteria). After examining the number of effects in each of these
categories for each variable, only the PTS results will be split by PTSD
diagnosis with 16 no mention, 16 in the mixed category, and 86 yeses.

\subsection{Calculations for Effect Size, Variance, and Confidence
Intervals}\label{calculations-for-effect-size-variance-and-confidence-intervals}

For our purposes, we used Cohen's (1988) standards for nomenclature for
small (0.20), medium (0.50), and large (0.80) \emph{d} values, although
it is important to note that Cohen himself suggested that these values
should be based on the area of study. Generally, however, these effect
size criteria are used within the social sciences. Each study
implemented a pre-test to post-test style repeated measures design,
usually with paired \emph{t}-tests, ANOVA, or regression analyses. The
means, standard deviations, and \emph{N} values were collected from each
study. In general, Cohen's \emph{d} values were calculated using the
following formula for paired \emph{t} using means and standard
deviations for each time point:

\[
{d_{av}} = \frac { M_1 - M_2 } { \frac { SD_1 + SD_2 } { 2 }}
\]

This equation is described in detail in Cumming (2012) as an alternative
to the traditional calculation of \emph{d} for paired samples \emph{t},
wherein the denominator is the standard deviation of the difference
scores:

\[
{d_{z}} = \frac { M_1 - M_2 } { SD_{diff} }
\]

This equation for \(d_{av}\) not only allows for calculations from
published articles that do not include \(SD_{diff}\) (i.e., most
articles included), but also has been shown to be less upwardly biased
than \(d_{z}\). Alternative formulas include controlling for \emph{r}
between paired levels, as described in Lakens (2013); however, these
values were not available in the selected articles, and Lakens also
recommends \(d_{av}\) as an effect size for paired designs. When only
mean differences and standard deviation of the difference scores were
available, the second equation for \(d_z\) was used.

We planned to use traditional and newer methods of meta-analysis,
following guidelines from Cooper, Hedges, \& Valentine (2009) and
Borenstein et al. (2007), as well as Van Aert et al. (2016). Sampling
variance of the effect sizes were estimated using the \emph{escalc()}
function from the \emph{metafor} package in \emph{R} (Viechtbauer,
2010). The variance formula was originally published in Morris \& DeShon
(2002) and is shown below:

\[
v = \frac { 1 } { n } (\frac { n - 1 } { n - 3 } )(1 + n*d^2) - \frac { d^2 } { [c(n-1)]^2}
\]

In this formula, \emph{n} is the number of paired observations, \emph{d}
is the calculated effect size, and \emph{c} is a correction factor,
wherein \emph{df} are \emph{n} -- 1 (Hedges, 1982):

\[
c = 1 - \frac { 3 } { 4*df - 1 }
\]

We used the \emph{metagen()} function in the \emph{metafor} package to
calculate both fixed and random effects models, which uses standard
error of the effect to calculate overall estimates of an effect and
their confidence intervals. Thus, we took the square root of the
variance estimate for standard error. Given these calculations, the goal
of this analysis was to calculate a combined effect size, along with a
confidence interval for study planning and an assessment of the
literature. A fixed effects model requires the assumption that there is
a true population effect size across all studies. By including multiple
measures of psychological outcomes, this assumption may be tenuous, and
therefore, a random effects model was also calculated. In random effects
models, the true effect is assumed to vary across studies (Borenstein et
al., 2007). For a fixed effects model, the effect sizes are weighted by
their inverse variance (\emph{v}; Sánchez-Meca \& Marín-Martínez, 2008),
which is calculated automatically in \emph{metafor} by:

\[
w_{i}^{FE} = \frac {1} {v}
\]

The advantage to this procedure is that analyses are weighted by their
precision, that is, that studies with more information (often, larger
samples), are given larger weights in the overall estimated effect size
(Borenstein et al., 2007). Random effects models are also weighted by
inverse variance, with an additional correction for variance between
studies, \(\tau^2_{DL}\), as described by DerSimonian \& Laird (1986):

\[
w_{i}^{RE} = \frac {1} {v + \tau^2_{DL}}
\]

Confidence intervals were calculated in two ways for this study. Cumming
(2012), Kelley (2007), and Smithson (2001) have shown that the
distribution of \emph{d} values are non-normal, and thus, CIs should be
estimated using the non-centrality parameter and a non-normal
distribution. These values were calculated using the functions in the
\emph{MOTE} library which iteratively estimates the appropriate
non-centrality parameter and converts back to \emph{d} values (i.e.,
non-centrality parameter divided by the square root of \emph{n};
Buchanan, Valentine, \& Scofield, 2017; Smithson, 2001, 2003). However,
the \emph{metafor} package in \emph{R} uses central distributions to
estimate CIs for each study and overall effect sizes. Therefore, we
present both sets of values for the interested reader, as meta-analytic
procedures have not implemented non-central distributions of effect
sizes.

\subsection{Additional Meta-Analytic
Techniques}\label{additional-meta-analytic-techniques}

\subsubsection{p-Curve and p-Uniform}\label{p-curve-and-p-uniform}

We used \emph{p}-curve.com to conduct a \emph{p}-curve analysis
(Simonsohn et al., 2014). The purpose of this type of analysis is to
detect true effects. Specifically, \emph{p}-curve is used to reveal
possible \emph{p}-hacking in published literature in order to decipher
whether or not a true effect exists. Broadly, \emph{p}-hacking occurs
when researchers use questionable research practices to create
significant results by manipulating dependent variables or covariates.
Additionally, authors may add participants if the initial findings are
not significant (Bruns \& Ioannidis, 2016). Researchers may also decide
to exclude participants for final analyses if that exclusion leads to a
significant difference (John, Loewenstein, \& Prelec, 2012). Thus, it is
necessary to distinguish between true and false effects in order to
effectively interpret effect sizes corresponding to those
\emph{p}-values. \emph{p}-curve accomplishes this task by examining the
distributions of the published \emph{p}-values. If an effect exists, or
rather the results should be interpreted as presented, the distribution
of \emph{p}-values will be positively skewed (Simonsohn et al., 2014).
If, however, no effect exists, then the distribution of \emph{p}-values
will be flat. \emph{p}-curve analyses ultimately provide evidence of
\emph{p}-hacking in groups of studies and has become an important tool
for interpreting meta-analyses. In order to accurately estimate effect
sizes because of scrutiny associated with effect size estimation of
\emph{p}-curve, we also conducted \emph{p}-uniform. \emph{p}-uniform
analyses, too, are interpreted by examining the distribution of
\emph{p}-values in a set of studies (Van Aert et al., 2016). However, it
is assumed that the population effect size equals the effect size from
the dataset. Because of this assumption, the population effect size is
referred to as uniform. This analysis also examines for publication bias
and presents the researcher with a corrected effect size. Publication
bias occurs when only select studies are published, usually only
significant studies, although many factors can bias a study's
publication (McShane, Böckenholt, \& Hansen, 2016). \emph{p}-uniform was
calculated from code provided by Van Aert (2017) on GitHub.

\subsubsection{PET-PEESE}\label{pet-peese}

Originally, meta-analyses relied on the calculation of Egger's
regression test which examined the relationship of the standard error
(predictor) to the effect size estimates (criterion). In this
regression, the intercept values were used to determine if effect size
measures were different than zero, by providing a meta-analytic estimate
(Egger, Davey Smith, Schneider, \& Minder, 1997; Stanley, 2005).
PET-PEESE analyses examine for publication bias by adapting parts from
Egger's traditional regression tests: PET (Precision Effect Test) and
PEESE (Precision Effect Estimate with Standard Error, Carter \&
McCullough, 2014). PET is a more reliable test of publication bias with
effect size estimates of zero, \(b_0\) = 0, while PEESE is more accurate
with non-zero effect size estimates, \(b_0 \neq\) 0 (Stanley \&
Doucouliagos, 2014). PET-PEESE was calculated using Hilgard's (2016)
code provided on GitHub.

\subsubsection{Selection Models}\label{selection-models}

Selection model analyses provide the researcher with a test of
publication bias and effect size estimates using maximum likelihood
estimation (Vevea \& Hedges, 1995; Vevea \& Woods, 2005). Using
selection models, researchers are able to discover effect size estimates
as well as evidence of publication bias (McShane et al., 2016) by using
a mixed general linear model to estimate these values. Selection models
were calculated with the \emph{weightr} package in \emph{R} (Coburn \&
Vevea, 2017).

\subsubsection{Trim and Fill}\label{trim-and-fill}

Trim and Fill analyses, in contrast to PET-PEESE, regress standard error
(criterion) and effect size estimates (predictor). Specifically, the
purpose of Trim and Fill techniques is to examine whether or not
publication bias may influence the regression equation (Carter \&
McCullough, 2014). Effect sizes and standard error terms are graphically
displayed on x and y-axes, respectively, in a funnel plot. If this
graphical representation indicates asymmetry, considered a gap of
missing data points in the lower center area of the plot, the study set
can be assumed to have studies that are both non-significant and small
in sample size (Van Assen, Van Aert, \& Wicherts, 2015). This funnel is
then trimmed until symmetry is achieved. Missing studies from the
symmetrical graph are imputed (filled) while maintaining the given
symmetry (Duval \& Tweedie, 2000). The meta-analytic effect size is then
estimated from the trimmed and filled funnel plot. Trim and fill
analyses, as well as funnel plots included below, were calculated with
the \emph{metafor} package.

\section{Results}\label{results}

\subsection{Posttraumatic Stress}\label{posttraumatic-stress-1}

\subsubsection{Overall Effect Size}\label{overall-effect-size}

As described above, both fixed effects and random effects models with
centralized confidence intervals are presented in Table
\ref{tab:PTStable}. Studies were examined for potential outliers using
the \emph{metafor} package in \emph{R}. This package calculates
traditional regression influence values, such as Cook's and hat values
(Cohen, 1988). These values indicate change in overall meta-analytic
model with and without the effect; thus, determining their impact on the
pooled effect size (Viechtbauer, 2010). Because published studies likely
represent the range of the sampling distribution of effect sizes, we
included the analyses with and without outliers to present evidence for
both paths a researcher might take when examining an overall effect.

2 outliers were detected with this procedure, all showing very large
effect sizes, average \emph{d} = 2.81. The fixed and random effects
estimates without these points are also included in Table
\ref{tab:PTStable}. Figures \ref{fig:ptspicoverall},
\ref{fig:ptspichyper}, \ref{fig:ptspicint}, and \ref{fig:ptspicavoid}
portray the effect sizes for PTS studies, separated by intrusions,
avoidance, hyperarousal, and total scores for easier viewing (i.e., over
100+ effect sizes did not fit easily on one combined graph). Although
these categories are not reflective of updated DSM-5 criteria,
researchers have not yet conducted enough studies using expressive
writing on PTS with updated PTSD criteria to warrant a meta-analysis.
Name acronym coding can be found in the data online. This forest plot
includes the non-centralized confidence interval calculated from the
\emph{MOTE} library (Buchanan et al., 2017). Shape size indicates study
weight, and these values were taken from the overall random effects
meta-analysis and normalized by dividing by the mean weight. The dashed
lines indicate the average non-weighted lower and upper confidence
interval limit for the non-centralized estimates. Overall, PTS studies
include a small effect size that appears to be significantly greater
than zero across all estimate types (fixed, random, with or without
outliers).

We further calculated the overall effect sizes by PTSD diagnosis
category using a random effects model. Studies only including
individuals with a diagnosis of PTSD exhibited a medium effect size
(before and after outlier exclusion): with outliers \emph{d} = 0.64
{[}0.48, 0.79{]}; without outliers \emph{d} = 0.55 {[}0.41, 0.69{]},
while studies not requiring (or listing) a PTSD diagnosis showed a small
to medium effect size: \emph{d} = 0.32 {[}0.24, 0.40{]}. Similarly, the
mixed category showed a small to medium effect size : \emph{d} = 0.35
{[}0.16, 0.54{]}. Complete estimates of all the following analyses split
by diagnosis are included online at \url{https://osf.io/4mjqt/}, and
their pattern of results is similar to the overall pattern here.

\begin{figure}[htbp]
\centering
\includegraphics{meta_markdown_files/figure-latex/ptspicoverall-1.pdf}
\caption{\label{fig:ptspicoverall}Effect sizes and their non-centralized
confidence interval for PTS total scores. Dashed lines indicated average
non-weighted lower and upper confidence interval limits. Diamond size
indicates normalized study weight from a random effects model. Y-axis
labels indicate citation and pairwise time combination, these labels can
be matched to the exact data by viewing the provided data online. Table
1 includes meta-analytic effect size for PTS overall.}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics{meta_markdown_files/figure-latex/ptspichyper-1.pdf}
\caption{\label{fig:ptspichyper}Effect sizes and their non-centralized
confidence interval for PTS Hyperarousal. Dashed lines indicated average
non-weighted lower and upper confidence interval limits. Diamond size
indicates normalized study weight from a random effects model. Y-axis
labels indicate citation and pairwise time combination, these labels can
be matched to the exact data by viewing the provided data online. Table
1 includes meta-analytic effect size for PTS overall.}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics{meta_markdown_files/figure-latex/ptspicint-1.pdf}
\caption{\label{fig:ptspicint}Effect sizes and their non-centralized
confidence interval for PTS Intrusion scores. Dashed lines indicated
average non-weighted lower and upper confidence interval limits. Diamond
size indicates normalized study weight from a random effects model.
Y-axis labels indicate citation and pairwise time combination, these
labels can be matched to the exact data by viewing the provided data
online. Table 1 includes meta-analytic effect size for PTS overall.}
\end{figure}

\begin{figure}[htbp]
\centering
\includegraphics{meta_markdown_files/figure-latex/ptspicavoid-1.pdf}
\caption{\label{fig:ptspicavoid}Effect sizes and their non-centralized
confidence interval for PTS Avoidance Scores. Dashed lines indicated
average non-weighted lower and upper confidence interval limits. Diamond
size indicates normalized study weight from a random effects model.
Y-axis labels indicate citation and pairwise time combination, these
labels can be matched to the exact data by viewing the provided data
online. Table 1 includes meta-analytic effect size for PTS overall.}
\end{figure}

\subsubsection{Homogeneity}\label{homogeneity}

A prerequisite for newer meta-analytic techniques includes the
assessment of homogeneity of the effects (Van Aert et al., 2016). Using
the \emph{metafor} package in \emph{R}, we calculated the
\emph{Q}-statistic and the \(I^2\) index (Cochran, 1954; Huedo-Medina,
Sánchez-Meca, Marín-Martínez, \& Botella, 2006). Significant values
imply inconsistencies across the variable or variables of interest and
are represented by \emph{Q}. In contrast, \(I^2\) indicates the
percentage of heterogeneity along with a 95\% CI. Both can, however, be
biased with a small number of experiments included for analyses
(Higgins, Thompson, Deeks, \& Altman, 2003; Huedo-Medina et al., 2006).
Thus, we sought to calculate an overall level of heterogeneity after
examining each variable separately before and after excluding outliers.
For PTS studies including outliers, we found significant heterogeneity,
\emph{Q}(162) = 776.74, \emph{p} \textless{} .001 and \(I^2\) = 79.1,
95\% CI{[}75.9 - 81.9{]}. These values were reduced slightly with the
exclusion of outliers, \emph{Q}(160) = 677.98, \emph{p} \textless{} .001
and \(I^2\) = 76.4, 95\% CI{[}72.6 - 79.7{]}. While heterogeneity is
present for PTS, some researchers indicate that heterogeneity is
inevitable ({\textbf{???}}), especially in analyses including a wide
range of studies.

\subsubsection{Power}\label{power}

Power was calculated in two different ways using the \emph{pwr} package
in \emph{R} (Champely, 2016). \emph{Post hoc} power was first calculated
using sample size and effect size statistics from each individual study.
Additionally, we calculated power using the study sample size and
estimated overall effect size from the random effects model with and
without outliers, as explained by Francis (2012) and Francis (2014). The
first estimate indicates the likelihood of finding an effect from our
sample statistics, while the second indicates the likelihood of finding
the true population effect size. If each study had been conducted on
only the change in the experimental group, 46.6\% of studies would have
been considered significant at \(\alpha\) \textless{} .05. The average
power of these studies based on their original study characteristics was
.48 (\emph{SD} = .36). Power for the random-effects meta-analytic effect
size with outliers was .52 (\emph{SD} = .25) and without outliers was
.49 (\emph{SD} = .25). Therefore, power consistently was around 40-50\%
for studies examining PTS, regardless of outlier effects. In these
studies, only 28.8\% achieved recommended 80\% power for their found
effect size, a smaller 24.5\% for the random-effect outlier effect size,
and even smaller 20.2\% for power calculations on the random-effect size
without the outliers. Overall, most of the studies in the current
meta-analysis do not achieve recommended .80 power for detecting true
effects, which may warrant caution in interpreting the overall effects
presented.

\subsubsection{Other Meta-Analytic
Estimates}\label{other-meta-analytic-estimates}

As noted in Van Aert et al. (2016), \emph{p}-curve and \emph{p}-uniform
analyses are upwardly biased when heterogeneity is high. Therefore, we
use caution when interpreting these analyses on PTS outcomes. As seen in
Table \ref{tab:PTStable}, the estimates for \emph{p}-uniform were higher
than other techniques, likely because of the focus on significant
\emph{p}-values and the great degree of heterogeneity described earlier.
\emph{P}-curve pictures can be found at \url{https://osf.io/4mjqt/}
online, and this analysis indicated evidentiary value at \emph{p}
\textless{} .001. Additionally, the \emph{p}-uniform analysis indicated
that there was likely no publication bias present, \emph{Z} = -5.71,
\emph{p} = 1.000. When examining the PET analysis, we found that the
intercept was significant, which indicated that PEESE was likely a
better estimator of the meta-analytic effect size. PEESE estimates were
lower than the original meta-analytic estimate, but confidence intervals
indicated that the effect is small to medium, and still larger than
zero. Selection models indicated a larger effect size, especially with
the random-effects models, and these effects were influenced by the
outliers found in the published studies. Trim and fill models are shown
in Table \ref{tab:PTStable}, and figures are included online. Nineteen
missing studies were imputed for both models with and without outliers.
Across all these effect size estimates, we found that expressive writing
was likely to decrease PTS symptoms in a small to moderate way. The
correlation of effect size with time between measurement times was
\(r = -.01\), 95\% CI \([-.17\), \(.14]\), \(t(161) = -0.15\),
\(p = .879\), and \(r = -.08\), 95\% CI \([-.23\), \(.08]\),
\(t(159) = -1.00\), \(p = .320\) without outliers. This result indicated
that the effect of expressive writing slightly decreased across time.
Together, these results suggest no evidence of publication bias, as well
as support our conclusion of a small to medium effect size for the
efficacy of expressive writing on PTS.

\begin{table}[tbp]
\begin{center}
\begin{threeparttable}
\caption{\label{tab:PTStable}Effect Size Estimates for PTS Results}
\small{
\begin{tabular}{lcccc}
\toprule
Model & Fixed Effects & Random Effects & Fixed No Outliers & Random No Outliers\\
\midrule
Overall Effects & 0.36 [0.34, 0.39] & 0.42 [0.35, 0.49] & 0.36 [0.33, 0.38] & 0.40 [0.33, 0.46]\\
$Z$ Values & 24.64, $p$ < .001 & 12.35, $p$ < .001 & 23.97, $p$ < .001 & 12.38, $p$ < .001\\
$p$-Uniform & 0.63 [0.54, 0.72] & - & 0.61 [0.52, 0.70] & -\\
PET & 0.09 [0.01, 0.18] & - & 0.14 [0.06, 0.22] & -\\
PEESE & 0.24 [0.20, 0.29] & - & 0.26 [0.22, 0.31] & -\\
Selection Models & 0.33 [0.28, 0.37] & 0.45 [0.33, 0.57] & 0.29 [0.24, 0.33] & 0.39 [0.27, 0.50]\\
Trim and Fill & 0.28 [0.25, 0.31] & 0.28 [0.21, 0.36] & 0.28 [0.25, 0.31] & 0.28 [0.21, 0.35]\\
\bottomrule
\addlinespace
\end{tabular}
}
\begin{tablenotes}[para]
\textit{Note.} [] indicates the 95 percent confidence interval for each effect size estimate.
\end{tablenotes}
\end{threeparttable}
\end{center}
\end{table}

\subsection{Postraumatic Growth}\label{postraumatic-growth}

\subsubsection{Overall Effect Size}\label{overall-effect-size-1}

Both fixed and random effects models with centralized confidence
intervals for PTG are presented in Table \ref{tab:PTGtable}. When
examining expressive writing on PTG, no outliers were detected. Fixed
and random effects estimates are included in Table \ref{tab:PTGtable},
while Figure \ref{fig:ptgpic} shows effect sizes for PTG studies where
shape size indicates the normalized weight of the study. Dashed lines
indicate non-weighted lower and upper confidence intervals for
non-centralized estimates. Overall, PTG studies indicated a negligible
to small effect size across both random and fixed effects models, and
the non-centralized confidence intervals indicated an effect that
crossed zero.

\begin{figure}[htbp]
\centering
\includegraphics{meta_markdown_files/figure-latex/ptgpic-1.pdf}
\caption{\label{fig:ptgpic}Effect sizes and their non-centralized confidence
interval for PTG outcome variables. Dashed lines indicated average
non-weighted lower and upper confidence interval limits. Diamond size
indicates normalized study weight from a random effects model. Y-axis
labels indicate citation and pairwise time combination, these labels can
be matched to the exact data by viewing the provided data online. Table
2 includes meta-analytic effect size for PTG.}
\end{figure}

\subsubsection{Homogeneity}\label{homogeneity-1}

Using the \emph{metafor} package in \emph{R}, we calculated both a
\emph{Q} statistic and \(I^2\) index. Since PTG studied did not contain
any outliers, we did not calculate two separate analyses to examine
heterogeneity both with and without outliers. We did not find
significant heterogeneity across PTG studies, \emph{Q}(20) = 14.18,
\emph{p} = .821 and \(I^2\) = 0.0, 95\% CI{[}0.0 - 25.3{]}. While
heterogeneity is typically expected, these results suggest that
individuals can be confident in the effect size interpretation for PTG.
\#\#\# Power

First, we calculated \emph{post hoc} power using both sample and effect
size statistics from individual studies. Individual studies examining
change in experimental groups showed that 9.5\% of studies would have
been considered significant at \(\alpha\) \textless{} .05. Average power
of PTG studies was .15 (\emph{SD} = .16). 0.0\% achieved recommended
80\% power for their found effect size. Additionally, we calculated
power using study sample size and estimated effect size from our random
effects model. Power for the true effect size was .08 (\emph{SD} = .02).
Again, 0.0\% achieved recommended 80\% power. These power results
suggest that studies examining the efficacy of expressive writing on PTG
were not adequately powered to detect effects. Therefore, the effect
size derived from these studies may not adequately represent the
relationship between expressive writing and PTG.

\subsubsection{Other Meta-Analytic
Estimates}\label{other-meta-analytic-estimates-1}

Due to no heterogeneity across PTG studies, we can use both
\emph{p}-curve and \emph{p}-uniform analyses with more confidence. A
pictorial representation of \emph{p}-curve can be found at
\url{https://osf.io/4mjqt/}. This analysis did not indicate evidentiary
value, \emph{p} = .75, as only two of the results would be considered
significant at \(\alpha\) \textless{} .05. \emph{p}-uniform estimates
are presented in Table \ref{tab:PTGtable}. Specifically, these analyses
indicated that there was no publication bias present, \emph{Z} = 0.70,
\emph{p} = .243. The \emph{p}-uniform estimates of the effect size for
PTG were negative, in contrast to the fixed and random effects overall
model. The confidence interval for this analysis indicates a wide range
of possible effects. In examining PET-PEESE analyses, we did not find a
significant intercept, indicating that PET is most likely a better
effect size estimator. PET analyses indicated that the effect size is
negligible to small, with our confidence interval crossing zero. These
results corroborated our original effect size calculations. Selection
models indicated negligible to small effect sizes, again wherein the
confidence interval includes zero effect. Trim and fill models are shown
in Table \ref{tab:PTGtable}, and figures are included online. Zero
studies were imputed for our model, and thus, the effect size estimate
is the same as the overall model. Across techniques, we found that
expressive writing has little to no effect on PTG. The correlation of
effect size across measurement times in PTG studies at subsequent time
points was \(r = .09\), 95\% CI \([-.36\), \(.50]\), \(t(19) = 0.38\),
\(p = .707\), and no change over time was found. In sum, no publication
bias was present, which is desired. However, the analyses suggest a wide
range of possible effects for the efficacy of expressive writing on PTG.

\begin{table}[tbp]
\begin{center}
\begin{threeparttable}
\caption{\label{tab:PTGtable}Effect Size Estimates for PTG Results}
\small{
\begin{tabular}{lcc}
\toprule
Model & Fixed Effects & Random Effects\\
\midrule
Overall Effects & 0.10 [0.02, 0.17] & 0.10 [0.02, 0.17]\\
$Z$ Values & 2.45, $p$ = .014 & 2.45, $p$ = .014\\
$p$-Uniform & -0.11 [-1.43, 0.42] & -\\
PET & 0.06 [-0.20, 0.32] & -\\
PEESE & 0.08 [-0.04, 0.20] & -\\
Selection Models & 0.09 [-0.01, 0.18] & 0.09 [-0.03, 0.20]\\
Trim and Fill & 0.10 [0.02, 0.17] & 0.10 [0.02, 0.17]\\
\bottomrule
\addlinespace
\end{tabular}
}
\begin{tablenotes}[para]
\textit{Note.} [] indicates the 95 percent confidence interval for each effect size estimate.
\end{tablenotes}
\end{threeparttable}
\end{center}
\end{table}

\subsection{Quality of Life}\label{quality-of-life-1}

\subsubsection{Overall Effect Size}\label{overall-effect-size-2}

Finally, for QOL, both fixed and random effects models with centralized
confidence intervals are presented in Table \ref{tab:QOLtable}. Two
outliers were detected with this procedure, average \emph{d} = -0.07.
While the average effect of these outliers indicates a small number, it
is important to note that these two outliers were the largest positive
and negative effects found from the Possemato, Ouimette, \& Geller
(2010) study. Fixed and random effects estimates without these points
are also included in Table \ref{tab:QOLtable}, while Figure
\ref{fig:qolpic} shows effect sizes for QOL studies. Overall, QOL
studies indicated a negligible to small effect that showed a
non-significant decrease in quality of life as a result of expressive
writing.

\begin{figure}[htbp]
\centering
\includegraphics{meta_markdown_files/figure-latex/qolpic-1.pdf}
\caption{\label{fig:qolpic}Effect sizes and their non-centralized confidence
interval for QOL outcome variables. Dashed lines indicated average
non-weighted lower and upper confidence interval limits. Diamond size
indicates normalized study weight from a random effects model. Y-axis
labels indicate citation and pairwise time combination, these labels can
be matched to the exact data by viewing the provided data online. Table
3 includes meta-analytic effect size for QOL.}
\end{figure}

\subsubsection{Homogeneity}\label{homogeneity-2}

For QOL studies including outliers, we found significant heterogeneity
from our random effects model, \emph{Q}(36) = 200.09, \emph{p}
\textless{} .001 and \(I^2\) = 82.0, 95\% CI{[}75.9 - 86.5{]}. After
excluding outliers, our random effects model still indicated
heterogeneity,\emph{Q}(34) = 93.18, \emph{p} \textless{} .001 and
\(I^2\) = 63.5, 95\% CI{[}47.6 - 74.6{]}. As mentioned, heterogeneity in
meta-analyses is expected ({\textbf{???}}) especially when utilizing
studies across diverse samples and methodologies.

\subsubsection{Power}\label{power-1}

In conducting \emph{post hoc} power using sample and effect size
statistics from individual studies, we found that 21.6\% of studies
would have been considered significant at \(\alpha\) \textless{} .05.
Average power based on actual study characteristics was .33 (\emph{SD} =
.32). Power for the random effects meta-analytic effect size with
outliers was .05 (\emph{SD} = .00) and without outliers was .05
(\emph{SD} = .00). Unfortunately, power was around 5\% for both random
effects models with and without outliers. In these studies, 18.9\%
achieved adequate power of 80\% on their found effect size, while 0.0\%
achieved 80\% power for our random effects model with outliers. Finally,
without outliers, 0.0\% achieved 80\% power. Similar to PTG, very few
studies were adequately powered at .80 to detect effects, warranting
caution in the interpretation of the aforementioned effect sizes.

\subsubsection{Other Meta-Analytic
Estimates}\label{other-meta-analytic-estimates-2}

We exert caution in interpreting \emph{p}-curve and \emph{p}-uniform
analyses on QOL outcomes with and without outliers due to heterogeneity.
As seen in Table \ref{tab:PTStable}, \emph{p}-uniform estimates were
stronger and positive than other techniques because of the high degree
of heterogeneity recently described. \emph{p}-curve pictures can be
found at the following OSF Link: \url{https://osf.io/4mjqt}. Eight
studies were significant at \(\alpha\) \textless{} .05, and the studies
indicated evidentiary value, \emph{p} = .004. \emph{p}-uniform analyses
did not indicate publication bias, \emph{Z} = -2.75, \emph{p} = .997. In
PET-PEESE analyses, we found that the intercept was not significant, and
therefore, PET was a better estimator of the meta-analytic effect. Table
\ref{tab:PTStable} indicates that both of these analyses estimate the
effect size around zero, with a confidence interval that includes zero.
Selection models correspondingly show small effects crossing zero,
except for random effects models with outliers, that appear to be
heavily influenced by the outliers. Trim and fill models are shown in
Table \ref{tab:QOLtable}, and figures are included online. No studies
were imputed for these analyses, and therefore, the effect size
estimates match the original meta-analysis. Overall, these results
appear to point to no effects, ranging across zero with several negative
estimates. Interestingly, the correlation of effect sizes across
measurement times with outliers was \(r = -.37\), 95\% CI \([-.62\),
\(-.05]\), \(t(35) = -2.33\), \(p = .026\) and \(r = -.64\), 95\% CI
\([-.80\), \(-.39]\), \(t(33) = -4.75\), \(p < .001\) without outliers.
The effect of expressive writing appears to be positive at short time
intervals and decreases into negative effects at longer time intervals.
Together, these analyses indicated no publication bias and support a
null effect. Although, these results should be taken into consideration
within the context of low power.

\begin{table}[tbp]
\begin{center}
\begin{threeparttable}
\caption{\label{tab:QOLtable}Effect Size Estimates for QOL Results}
\small{
\begin{tabular}{lcccc}
\toprule
Model & Fixed Effects & Random Effects & Fixed No Outliers & Random No Outliers\\
\midrule
Overall Effects & -0.01 [-0.07, 0.05] & -0.01 [-0.16, 0.13] & -0.01 [-0.07, 0.05] & -0.01 [-0.11, 0.09]\\
$Z$ Values & -0.33, $p$ = .745 & -0.18, $p$ = .860 & -0.25, $p$ = .805 & -0.20, $p$ = .838\\
$p$-Uniform & 0.79 [0.33, 1.61] & - & 0.62 [0.10, 0.96] & -\\
PET & 0.05 [-0.26, 0.36] & - & 0.05 [-0.29, 0.38] & -\\
PEESE & 0.00 [-0.17, 0.17] & - & 0.00 [-0.19, 0.19] & -\\
Selection Models & -0.06 [-0.12, 0.01] & 0.51 [-0.09, 1.12] & -0.04 [-0.11, 0.03] & 0.05 [-0.15, 0.24]\\
Trim and Fill & -0.01 [-0.07, 0.05] & -0.01 [-0.16, 0.13] & -0.01 [-0.07, 0.05] & -0.01 [-0.11, 0.09]\\
\bottomrule
\addlinespace
\end{tabular}
}
\begin{tablenotes}[para]
\textit{Note.} [] indicates the 95 percent confidence interval for each effect size estimate.
\end{tablenotes}
\end{threeparttable}
\end{center}
\end{table}

\section{Discussion}\label{discussion}

In examining pre- to post-test comparisons across each variable
separately, we found that PTS studies indicated a small effect size
across all meta-analytic estimates. This suggests that a brief,
easy-to-administer intervention can produce positive outcomes. As
mentioned, PTS is operationally defined as re-experiencing thoughts and
feelings associated with a traumatic event and subsequently seeking to
avoid these thoughts and feelings. DSM-IV criteria for a PTSD diagnosis
include exposure to a traumatic event, intrusions, avoidance, and
hyperarousal. Interestingly, those studies requiring a diagnosis of PTSD
for inclusion resulted in a medium effect size, while those studies not
requiring a PTSD diagnosis resulted in a small to medium effect size.
These results suggest that those with clinical symptoms of PTSD may
benefit more from expressive writing interventions. Further, these
results are in contrast to recently-conducted studies, which suggest
that those with subclinical symptoms benefit more from expressive
writing tasks (Di Blasio et al., 2015; Sloan et al., 2011).

While both conditions exhibited effects, the difference in magnitude is
difficult to pinpoint. One possible explanation for these alternative
findings is the lack of adequately powered studies in the PTS condition,
which may lead to a misrepresentation of the true population effect.
Although, Sloan et al. (2018) recently conducted a noninferiority trial
comparing WET, an evidence-based protocol (5 sessions), to Cognitive
Processing Therapy (12 sessions) and found WET to be noninferior. Their
protocol included a treatment rationale as well as psychoeducation for
PTSD prior to commencing treatment. In order to participate in this
study, individuals were required to have a diagnosis of PTSD. Studies
from this protocol were also included in the analysis condition
requiring a diagnosis of PTSD. It is therefore possible that
psycheducation and a treatment rationale provide additional benefits
above and beyond simply writing. Additionally, perhaps individuals not
meeting criteria for PTSD do not engage in the maladaptive avoidance
behaviors at a higher frequency than individuals meeting diagnostic
criteria. In this case, an intervention with roots in imaginal exposure
(one of the proposed mechanisms) may be less efficacious for individuals
not avoiding thoughts and physiological sensations. Another explanation
may be heterogeneity, where effects are unequal across included studies.
While heterogeneity is expected, significant heterogeneity may
misrepresent the true effect across those studies requiring and not
requiring a PTSD diagnosis. Given that expressive writing is an
innocuous, easy-to-administer intervention, even small effect sizes
should be considered important when interpreting these results. While
small, these effect sizes exhibit a profound impact of expressive
writing on PTS.

Both PTG and QOL studies indicated a negligible to small effect size
using random effects models. Although the PTG effect in our overall
meta-analysis estimate was significant, other methods indicate this
small effect is likely not different from zero. These findings may be
due to the lack of power in each of these conditions, given that a very
low percentage of studies achieved adequate power. These results should
also be considered within the context of the intervention. Perhaps
simply writing about a stressful or traumatic event was unable promote
positive change above and beyond symptom reduction (i.e., low dose).
Indeed, conceptualizations of PTG suggest that various forms of social
support and other contextual contingencies are imperative for growth
after a trauma. As mentioned, PTG is characterized into building social
connections, behaviorally activating towards new life values and
appreciating those values/experiences, uncovering personal strengths,
and spiritual changes. An intervention that only targets the thoughts
and physiological sensations may not promote PTG, given its limited (but
important) focus on internal events. For QOL, aside from low power, null
results may also be due to the conceptualization of QOL, which suggests
that QOL is achieved through reactions to life events and experiences.
Expressive writing interventions do not address these contextual factors
(i.e., life experiences), which may be a possible explanations for the
null findings.

Additionally, our analyses focus on the change for the experimental
group across time, rather than an experimental group to a control group.
This focus allowed us to estimate the changes for individuals who
received a WED/WET intervention, therefore estimating the impact on
participants who used written expression. Potentially, these effects
could be contributed to other factors (such as the simple passage of
time), but we demonstrate here that for both PTS and PTG, there was no
relationship between effect size and time. For QOL studies, a medium to
large negative correlation was found. A negative relationship between
time and effect size implies that writing tasks were more effective in
the initial time points, and effects decreased over longer time spans.

The authors note several limitations. Generally, ineffective emotional
expression may be a contributing factor. If participants/clients are not
deeply engaged with the material, an expressive writing task may not be
effective, as Pennebaker \& Graybeal (2001) imply that connectedness is
an important factor for the task. However, it may be difficult to
implement a check for engagement in these types of research designs.
Doing so may also set a context that will inhibit emotional processing
and general responses. Research on expressive writing has found a wide
range of outcomes for different variables (Frattaroli, 2006), and these
various results may explain the large heterogeneity found in this study.
Encouragingly, we did not find much evidence of publication bias, and
therefore, these estimates may represent a true population effect size.
Regardless, methodology of expressive writing studies is variable, as it
is applied in different forms across different contexts. Ideally, it
would be possible to control for these varied instructions and
protocols. However, this is simply not feasible, as most studies do not
use measures that examine how engaged an individual is with the
material. As such, this current meta-analysis sought to provide readers
with a global effect of expressive writing on the aforementioned outcome
variables. More studies are needed to examine potential moderating
effects of participant engagement.

The authors also note limitations in regards to the specific outcome
variables. The nature of the construct of PTG makes it difficult to
analyze rigorously. For example, on the Posttraumatic Growth Inventory
(commonly used to study PTG), one could respond 0 to the item \enquote{I
have a greater appreciation for the value in my own life} because they
already had a high level of appreciation in their life (i.e., ceiling
effect). This conceptual issue may account for the non-effect of
expressive writing on PTG. Logically, it would be difficult to determine
whether or not an individual experiences growth from trauma without
having experienced trauma. In conducting the literature search for the
present meta-analysis, an insufficient number of studies requiring a
diagnosis of PTSD employed PTG as an outcome variable. Thus, it was
difficult to determine whether participants in the studies employed had
experienced trauma in line with DSM-IV criteria. For PTS, studies not
specifying whether or not participants had a diagnosis of PTSD were
included. It is possible that studies included in the subclinical
symptom category did in fact include participants without PTSD diagnosis
(perhaps it was simply not assessed by means of a structured clinical
interview). It is also crucial to consider mainstream issues not
specific to expressive writing and the outcome variables utilized in the
present study.

The psychological scientific community has shifted focus to
reproducibility and research design in the last several years (Nelson,
Simmons, \& Simonsohn, 2018), and much of this discussion has focused on
adequately powering studies for publication (Bakker et al., 2016;
Maxwell, Lau, \& Howard, 2015). Maxwell et al. (2015) and Open Science
Collaboration (2015) have shown that the \enquote{replication crisis}
may be attributed to low power in published studies. The power found in
the current meta-analysis was very poor, with very few studies reaching
the suggested 80\% criterion to adequately power their study. This
result was the same when considering individual study characteristics or
the estimate true population effect size. Research by Bakker et al.
(2016) indicates that researchers' intuitions about power are
particularly poor, and many studies could benefit from more informed
power analyses. Although, personnel and time required to conduct an
expressive writing study is high. While the expressive writing task
itself is relatively easy to administer, screening multiple participants
and collecting data at multiple time points is time consuming. Anderson,
Kelley, \& Maxwell (2017) recently published a primer on power, with an
online application to help with sample size planning for many types of
research designs. Additionally, we encourage researchers to report power
analyses of studies in order to better understand methodology for
replication and reproducibility.

Meta-analyses, while useful tools to pool for population effect sizes,
contain various limitations to their usefulness (Van Elk et al., 2015).
As mentioned previously, these analyses can be affected by high
heterogeneity, which was found in this study (Van Aert et al., 2016).
Selection models have been criticized when using a smaller number of
studies (Van Assen et al., 2015), and trim and fill analyses may not
always estimate accurate confidence intervals and funnel plots may be
biased with heterogeneity (Terrin, Schmid, Lau, \& Olkin, 2003). When
focusing on improving the psychological sciences, Van Elk et al. (2015)
suggest that the reliability and size of effects may be best elucidated
by conducting large preregistered studies. This suggestion will also
improve the outlook for power in published studies, and projects such as
Many Labs and the Psychological Science Accelerator can aide in
subsidizing large samples (Klein et al., 2014; Moshontz et al., 2018).
For example, studies can be proposed to the Psychological Science
Accelerator and labs across the globe can be recruited to improve sample
size for a study, which is a similar procedure to the Many Labs
projects. Distributed networks of research teams can solve the problems
with power that are present across all types of psychological research
(Bakker et al., 2016). Even with limitations, meta-analyses allow
researchers to examine the state of a research area, and we find
potential with expressive writing on reducing PTS symptoms, and an
overall need for better sample size and power planning for studies.

\newpage

\section{References}\label{references}

\setlength{\parindent}{-0.5in} \setlength{\leftskip}{0.5in}

\hypertarget{refs}{}
\hypertarget{ref-AmericanPsychiatricAssociation2013}{}
American Psychiatric Association. (2013). \emph{Diagnostic and
statistical manual of mental disorders} (Fifth.). Washington, DC:
American Psychiatric Association.
doi:\href{https://doi.org/10.1176/appi.books.9780890425596.744053}{10.1176/appi.books.9780890425596.744053}

\hypertarget{ref-Anderson2017a}{}
Anderson, S. F., Kelley, K., \& Maxwell, S. E. (2017). Sample-size
planning for more accurate statistical power: A method adjusting sample
effect sizes for publication bias and uncertainty. \emph{Psychological
Science}, \emph{28}(11), 1547--1562.
doi:\href{https://doi.org/10.1177/0956797617723724}{10.1177/0956797617723724}

\hypertarget{ref-Aslam2013}{}
Aslam, N., \& Kamal, A. (2013). Gender differences in distress
responses, rumination patterns, perceived social support and
posttraumatic growth among flood affected individuals. \emph{Journal of
Pakistan Psychiatric Society}, \emph{10}, 86--90.

\hypertarget{ref-Aust2017}{}
Aust, F., \& Barth, M. (2017). papaja: Create APA manuscripts with R
Markdown. Retrieved from \url{https://github.com/crsh/papaja}

\hypertarget{ref-Bakker2016}{}
Bakker, M., Hartgerink, C. H. J., Wicherts, J. M., \& Van Der Maas, H.
L. J. (2016). Researchers' intuitions about power in psychological
research. \emph{Psychological Science}, \emph{27}(8), 1069--1077.
doi:\href{https://doi.org/10.1177/0956797616647519}{10.1177/0956797616647519}

\hypertarget{ref-Bodor2002}{}
Bodor, N. Z. (2002). \emph{The health effects of emotional disclosure
for individuals with Type 1 diabetes} (PhD thesis No. 10-B).

\hypertarget{ref-Borenstein2007}{}
Borenstein, M., Hedges, L. V., \& Rothstein, H. (2007). Meta-analysis
fixed effect vs. random effects. Retrieved from
\href{https://www.meta-analysis.com/downloads/Meta-analysis\%20fixed\%20effect\%20vs\%20random\%20effects\%20072607.pdf}{https://www.meta-analysis.com/downloads/Meta-analysis fixed effect vs random effects 072607.pdf}

\hypertarget{ref-Bruns2016}{}
Bruns, S. B., \& Ioannidis, J. P. A. (2016). p-Curve and p-Hacking in
observational research. \emph{PLOS ONE}, \emph{11}(2), e0149144.
doi:\href{https://doi.org/10.1371/journal.pone.0149144}{10.1371/journal.pone.0149144}

\hypertarget{ref-Buchanan2017}{}
Buchanan, E. M., Valentine, K. D., \& Scofield, J. E. (2017). MOTE.
Retrieved from \url{https://github.com/doomlab/MOTE}

\hypertarget{ref-Carter2014}{}
Carter, E. C., \& McCullough, M. E. (2014). Publication bias and the
limited strength model of self-control: Has the evidence for ego
depletion been overestimated? \emph{Frontiers in Psychology},
\emph{5}(July), 1--11.
doi:\href{https://doi.org/10.3389/fpsyg.2014.00823}{10.3389/fpsyg.2014.00823}

\hypertarget{ref-Champely2016}{}
Champely, S. (2016). pwr: Basic functions for power analysis. R package
version 1.2-0. Retrieved from
\url{https://cran.r-project.org/package=pwr}

\hypertarget{ref-Cobb2006}{}
Cobb, A. R., Tedeschi, R. G., Calhoun, L. G., \& Cann, A. (2006).
Correlates of posttraumatic growth in survivors of intimate partner
violence. \emph{Journal of Traumatic Stress}, \emph{19}(6), 895--903.
doi:\href{https://doi.org/10.1002/jts.20171}{10.1002/jts.20171}

\hypertarget{ref-Coburn2017}{}
Coburn, K. M., \& Vevea, J. L. (2017). Weightr. Retrieved from
\url{https://cran.r-project.org/web/packages/weightr/index.html}

\hypertarget{ref-Cochran1954}{}
Cochran, W. G. (1954). Some methods for strengthening the common
\(\chi\) 2 tests. \emph{Biometrics}, \emph{10}(4), 417--451.
doi:\href{https://doi.org/10.2307/3001616}{10.2307/3001616}

\hypertarget{ref-Cohen1988}{}
Cohen, J. (1988). \emph{Statistical power analysis for the behavioral
sciences} (2nd ed.). Hillsdale, NJ: Earlbaum.

\hypertarget{ref-Cooper2009}{}
Cooper, H., Hedges, L. V., \& Valentine, J. (2009). \emph{The handbook
of research synthesis and meta-analysis} (2nd ed.). New York, NY:
Russell Sage Foundation.

\hypertarget{ref-Costanza2007}{}
Costanza, R., Fisher, B., Ali, S., Beer, C., Bond, L., Boumans, R.,
\ldots{} Snapp, R. (2007). Quality of life: An approach integrating
opportunities, human needs, and subjective well-being. \emph{Ecological
Economics}, \emph{61}(2-3), 267--276.
doi:\href{https://doi.org/10.1016/j.ecolecon.2006.02.023}{10.1016/j.ecolecon.2006.02.023}

\hypertarget{ref-Crespo2016}{}
Crespo, M., \& Gomez, M. M. (2016). Diagnostic concordance of DSM-IV and
DSM-5 posttraumatic stress disorder (PTSD) in a clinical sample.
\emph{Psicothema}, \emph{28}(2), 161--166.
doi:\href{https://doi.org/10.7334/psicothema2015.213}{10.7334/psicothema2015.213}

\hypertarget{ref-Cumming2012}{}
Cumming, G. (2012). \emph{Understanding the new statistics: Effect
sizes, confidence intervals, and meta-analysis}. New York, NY:
Routledge.

\hypertarget{ref-Dean2016}{}
Dean, J., Potts, H. W., \& Barker, C. (2016). Direction to an internet
support group compared with online expressive writing for people with
depression and anxiety: A randomized trial. \emph{Journal of Medical
Internet Research}, \emph{3}(2), e12.
doi:\href{https://doi.org/10.2196/mental.5133}{10.2196/mental.5133}

\hypertarget{ref-DerSimonian1986}{}
DerSimonian, R., \& Laird, N. (1986). Meta-analysis in clinical trials.
\emph{Controlled Clinical Trials}, \emph{7}(3), 177--188.
doi:\href{https://doi.org/10.1016/0197-2456(86)90046-2}{10.1016/0197-2456(86)90046-2}

\hypertarget{ref-Blasio2015a}{}
Di Blasio, P., Camisasca, E., Caravita, S. C. S., Ionio, C., Milani, L.,
Valtolina, G. G., \ldots{} Valtolina, G. G. (2015). The effects of
expressive writing on postpartum depression and posttraumatic stress
symptoms. \emph{Psychological Reports}, \emph{117}(3), 856--882.
doi:\href{https://doi.org/10.2466/02.13.PR0.117c29z3}{10.2466/02.13.PR0.117c29z3}

\hypertarget{ref-Dursun2016}{}
Dursun, P., Steger, M. F., Bentele, C., \& Schulenberg, S. E. (2016).
Meaning and posttraumatic growth among survivors of the September 2013
Colorado floods. \emph{Journal of Clinical Psychology}, \emph{72}(12),
1247--1263.
doi:\href{https://doi.org/10.1002/jclp.22344}{10.1002/jclp.22344}

\hypertarget{ref-Duval2000}{}
Duval, S., \& Tweedie, R. (2000). Trim and fill: A simple
funnel-plot-based method of testing and adjusting for publication bias
in meta-analysis. \emph{Biometrics}, \emph{56}(2), 455--463.
doi:\href{https://doi.org/10.1111/j.0006-341X.2000.00455.x}{10.1111/j.0006-341X.2000.00455.x}

\hypertarget{ref-Egger1997}{}
Egger, M., Davey Smith, G., Schneider, M., \& Minder, C. (1997). Bias in
meta-analysis detected by a simple, graphical test. \emph{British
Medical Journal}, \emph{315}(7109), 629--634.
doi:\href{https://doi.org/10.1136/bmj.316.7129.469}{10.1136/bmj.316.7129.469}

\hypertarget{ref-Esterling1990}{}
Esterling, B. A., Antoni, M. H., Kumar, M., \& Schneiderman, N. (1990).
Emotional repression, stress disclosure responses, and Epstein-Barr
viral capsid antigen titers. \emph{Psychosomatic Medicine}, \emph{52},
397--410.
doi:\href{https://doi.org/10.1097/00006842-199007000-00002}{10.1097/00006842-199007000-00002}

\hypertarget{ref-Fawzy1993}{}
Fawzy, N. W., Fawzy, N. W., Hyun, C. S., Elashoff, R., Guthrie, D.,
Fahey, J. L., \& Morton, D. L. (1993). Malignant melanoma. Effects of an
early structured psychiatric intervention, coping, and affective state
on recurrence and survival 6 years later. \emph{Archives of General
Psychiatry}, \emph{50}(9), 681--689.
doi:\href{https://doi.org/10.1001/archpsyc.1993.01820210015002}{10.1001/archpsyc.1993.01820210015002}

\hypertarget{ref-Francis2012}{}
Francis, G. (2012). Publication bias and the failure of replication in
experimental psychology. \emph{Psychonomic Bulletin \& Review},
\emph{19}(6), 975--991.
doi:\href{https://doi.org/10.3758/s13423-012-0322-y}{10.3758/s13423-012-0322-y}

\hypertarget{ref-Francis2014}{}
Francis, G. (2014). The frequency of excess success for articles in
Psychological Science. \emph{Psychonomic Bulletin \& Review},
\emph{21}(5), 1180--1187.
doi:\href{https://doi.org/10.3758/s13423-014-0601-x}{10.3758/s13423-014-0601-x}

\hypertarget{ref-Frankl1959}{}
Frankl, V. (1959). \emph{Man's search for meaning} (3rd ed.). Boston,
MA: Beacon Press.

\hypertarget{ref-Frattaroli2006}{}
Frattaroli, J. (2006). Experimental disclosure and its moderators: A
meta-analysis. \emph{Psychological Bulletin}, \emph{132}(6), 823--865.
doi:\href{https://doi.org/10.1037/0033-2909.132.6.823}{10.1037/0033-2909.132.6.823}

\hypertarget{ref-Frisina2004a}{}
Frisina, P. G., Borod, J. C., \& Lepore, S. J. (2004). A meta-analysis
of the effects of written emotional disclosure on the health outcomes of
clinical populations. \emph{The Journal of Nervous and Mental Disease},
\emph{192}(9), 629--634.
doi:\href{https://doi.org/10.1097/01.nmd.0000138317.30764.63}{10.1097/01.nmd.0000138317.30764.63}

\hypertarget{ref-Garcia-Oliva2016}{}
García-Oliva, C., \& Piqueras, J. A. (2016). Experiential avoidance and
technological addictions in adolescents. \emph{Journal of Behavioral
Addictions}, \emph{5}(2), 293--303.
doi:\href{https://doi.org/10.1556/2006.5.2016.041}{10.1556/2006.5.2016.041}

\hypertarget{ref-Gentes2014}{}
Gentes, E. L., Dennis, P. A., Kimbrel, N. A., Rissling, M. B., Beckham,
J. C., \& Calhoun, P. S. (2014). DSM-5 posttraumatic stress disorder:
Factor structure and rates of diagnosis. \emph{Journal of Psychiatric
Research}, \emph{59}(1), 60--67.
doi:\href{https://doi.org/10.1016/j.jpsychires.2014.08.014}{10.1016/j.jpsychires.2014.08.014}

\hypertarget{ref-Glass1976}{}
Glass, G. V. (1976). Primary, secondary, and meta-analysis of research.
\emph{Educational Researcher}, \emph{5}(10), 3--8.
doi:\href{https://doi.org/10.3102/0013189X005010003}{10.3102/0013189X005010003}

\hypertarget{ref-Gortner2006}{}
Gortner, E. M., Rude, S. S., \& Pennebaker, J. W. (2006). Benefits of
expressive writing in lowering rumination and depressive symptoms.
\emph{Behavior Therapy}, \emph{37}(3), 292--303.
doi:\href{https://doi.org/10.1016/j.beth.2006.01.004}{10.1016/j.beth.2006.01.004}

\hypertarget{ref-Hedges1982}{}
Hedges, L. V. (1982). Estimation of effect size from a series of
independent experiments. \emph{Psychological Bulletin}, \emph{92}(2),
490--499.
doi:\href{https://doi.org/10.1037/0033-2909.92.2.490}{10.1037/0033-2909.92.2.490}

\hypertarget{ref-Higgins2003}{}
Higgins, J. P. T., Thompson, S. G., Deeks, J. J., \& Altman, D. G.
(2003). Measuring inconsistency in meta-analyses. \emph{British Medical
Journal}, \emph{327}(7414), 557--560.
doi:\href{https://doi.org/10.1136/bmj.327.7414.557}{10.1136/bmj.327.7414.557}

\hypertarget{ref-Hilgard2016}{}
Hilgard, J. (2016). PETPEESE. GitHub. Retrieved from
\url{https://github.com/Joe-Hilgard/PETPEESE}

\hypertarget{ref-Huedo-Medina2006}{}
Huedo-Medina, T. B., Sánchez-Meca, J., Marín-Martínez, F., \& Botella,
J. (2006). Assessing heterogeneity in meta-analysis: Q statistic or I²
index? \emph{Psychological Methods}, \emph{11}(2), 193--206.
doi:\href{https://doi.org/10.1037/1082-989X.11.2.193}{10.1037/1082-989X.11.2.193}

\hypertarget{ref-John2012}{}
John, L. K., Loewenstein, G., \& Prelec, D. (2012). Measuring the
prevalence of questionable research practices with incentives for truth
telling. \emph{Psychological Science}, \emph{23}(5), 524--532.
doi:\href{https://doi.org/10.1177/0956797611430953}{10.1177/0956797611430953}

\hypertarget{ref-Kelley2007}{}
Kelley, K. (2007). Confidence intervals for standardized effect sizes.
\emph{Journal of Statistical Software}, \emph{20}(8), 1--24.
doi:\href{https://doi.org/10.18637/jss.v020.i08}{10.18637/jss.v020.i08}

\hypertarget{ref-Klein2014a}{}
Klein, R. A., Ratliff, K. A., Vianello, M., Adams, R. B., Bahník, Š.,
Bernstein, M. J., \ldots{} Nosek, B. A. (2014). Investigating variation
in replicability. \emph{Social Psychology}, \emph{45}(3), 142--152.
doi:\href{https://doi.org/10.1027/1864-9335/a000178}{10.1027/1864-9335/a000178}

\hypertarget{ref-Klump2008}{}
Klump, M. C. (2008). Posttraumatic stress disorder and sexual assault in
women. \emph{Journal of College Student Development}, \emph{8225}(May
2014), 37--41.
doi:\href{https://doi.org/10.1300/J035v21n02}{10.1300/J035v21n02}

\hypertarget{ref-Kross2011}{}
Kross, E., \& Ayduk, O. (2011). Making meaning out of negative
experiences by self-distancing. \emph{Current Directions in
Psychological Science}, \emph{20}(3), 187--191.
doi:\href{https://doi.org/10.1177/0963721411408883}{10.1177/0963721411408883}

\hypertarget{ref-Lakens2013}{}
Lakens, D. (2013). Calculating and reporting effect sizes to facilitate
cumulative science: A practical primer for t-tests and ANOVAs.
\emph{Frontiers in Psychology}, \emph{4}.
doi:\href{https://doi.org/10.3389/fpsyg.2013.00863}{10.3389/fpsyg.2013.00863}

\hypertarget{ref-Levitt2004}{}
Levitt, J. T., Brown, T. A., Orsillo, S. M., \& Barlow, D. H. (2004).
The effects of acceptance versus suppression of emotion on subjective
and psychophysiological response to carbon dioxide challenge in patients
with panic disorder. \emph{Behavior Therapy}, \emph{35}(4), 747--766.
doi:\href{https://doi.org/10.1016/S0005-7894(04)80018-2}{10.1016/S0005-7894(04)80018-2}

\hypertarget{ref-Lieberman2006}{}
Lieberman, M. A., \& Goldstein, B. A. (2006). Not all negative emotions
are equal: The role of emotional expression in online support groups for
women with breast cancer. \emph{Psycho-Oncology}, \emph{15}(2),
160--168. doi:\href{https://doi.org/10.1002/pon.932}{10.1002/pon.932}

\hypertarget{ref-Marx2005}{}
Marx, B. P., \& Sloan, D. M. (2005). Peritraumatic dissociation and
experiential avoidance as predictors of posttraumatic stress
symptomatology. \emph{Behaviour Research and Therapy}, \emph{43}(5),
569--583.

\hypertarget{ref-Maxwell2015}{}
Maxwell, S. E., Lau, M. Y., \& Howard, G. S. (2015). Is psychology
suffering from a replication crisis? What does ``failure to replicate''
really mean? \emph{American Psychologist}, \emph{70}(6), 487--498.
doi:\href{https://doi.org/10.1037/a0039400}{10.1037/a0039400}

\hypertarget{ref-McShane2016}{}
McShane, B. B., Böckenholt, U., \& Hansen, K. T. (2016). Adjusting for
publication bias in meta-analysis. \emph{Perspectives on Psychological
Science}, \emph{11}(5), 730--749.
doi:\href{https://doi.org/10.1177/1745691616662243}{10.1177/1745691616662243}

\hypertarget{ref-Mogk2006}{}
Mogk, C., Otte, S., Reinhold-Hurley, B., \& Kröner-Herwig, B. (2006).
Health effects of expressive writing on stressful or traumatic
experiences - a meta-analysis. \emph{Psychosocial Medicine}, \emph{3},
Doc06.

\hypertarget{ref-Morris2002}{}
Morris, S. B., \& DeShon, R. P. (2002). Combining effect size estimates
in meta-analysis with repeated measures and independent-groups designs.
\emph{Psychological Methods}, \emph{7}(1), 105--125.
doi:\href{https://doi.org/10.1037/1082-989X.7.1.105}{10.1037/1082-989X.7.1.105}

\hypertarget{ref-Moshontz2018}{}
Moshontz, H., Campbell, L., Ebersole, C. R., IJzerman, H., Urry, H. L.,
Forscher, P. S., \ldots{} Chartier, C. R. (2018). The Psychological
Science Accelerator: Advancing psychology through a distributed
collaborative network. \emph{Advances in Methods and Practices in
Psychological Science}, 251524591879760.
doi:\href{https://doi.org/10.1177/2515245918797607}{10.1177/2515245918797607}

\hypertarget{ref-Nelson2018}{}
Nelson, L. D., Simmons, J., \& Simonsohn, U. (2018). Psychology's
renaissance. \emph{Annual Review of Psychology}, \emph{69}(1), 511--534.
doi:\href{https://doi.org/10.1146/annurev-psych-122216-011836}{10.1146/annurev-psych-122216-011836}

\hypertarget{ref-Niles2014}{}
Niles, A. N., Haltom, K. E., Mulvenna, C. M., Lieberman, M. D., \&
Stanton, A. L. (2014). Randomized controlled trial of expressive writing
for psychological and physical health: The moderating role of emotional
expressivity. \emph{Anxiety, Stress and Coping}, \emph{27}(1), 1--17.
doi:\href{https://doi.org/10.1080/10615806.2013.802308}{10.1080/10615806.2013.802308}

\hypertarget{ref-OpenScienceCollaboration2015}{}
Open Science Collaboration. (2015). Estimating the reproducibility of
psychological science. \emph{Science}, \emph{349}(6251),
aac4716--aac4716.
doi:\href{https://doi.org/10.1126/science.aac4716}{10.1126/science.aac4716}

\hypertarget{ref-Pennebaker1989}{}
Pennebaker, J. W. (1989). Confession, inhibition, and disease. In L.
Berkowitz (Ed.), \emph{Advances in experimental social psychology} (Vol.
22, pp. 211--244). Academic Press.
doi:\href{https://doi.org/10.1016/S0065-2601(08)60309-3}{10.1016/S0065-2601(08)60309-3}

\hypertarget{ref-Pennebaker1986}{}
Pennebaker, J. W., \& Beall, S. K. (1986). Confronting a traumatic
event: Toward an understanding of inhibition and disease. \emph{Journal
of Abnormal Psychology}, \emph{95}(3), 274--281.
doi:\href{https://doi.org/10.1037//0021-843X.95.3.274}{10.1037//0021-843X.95.3.274}

\hypertarget{ref-Pennebaker2001}{}
Pennebaker, J. W., \& Graybeal, A. (2001). Patterns of natural language
use: Disclosure, personality, and social integration. \emph{Current
Directions in Psychological Science}, \emph{10}(3), 90--93.
doi:\href{https://doi.org/10.1111/1467-8721.00123}{10.1111/1467-8721.00123}

\hypertarget{ref-Possemato2010}{}
Possemato, K., Ouimette, P., \& Geller, P. (2010). Internet-based
expressive writing for kidney transplant recipients: Effects on
posttraumatic stress and quality of life. \emph{Traumatology},
\emph{16}(1), 49--54.
doi:\href{https://doi.org/10.1177/1534765609347545}{10.1177/1534765609347545}

\hypertarget{ref-Rachman1980}{}
Rachman, S. (1980). Emotional processing. \emph{Behaviour Research and
Therapy}, \emph{18}(1), 51--60.
doi:\href{https://doi.org/10.1016/0005-7967(80)90069-8}{10.1016/0005-7967(80)90069-8}

\hypertarget{ref-Reinhold2018}{}
Reinhold, M., Bürkner, P. C., \& Holling, H. (2018). Effects of
expressive writing on depressive symptoms---A meta-analysis.
\emph{Clinical Psychology: Science and Practice}, \emph{25}(1).
doi:\href{https://doi.org/10.1111/cpsp.12224}{10.1111/cpsp.12224}

\hypertarget{ref-Sanchez-Meca2008a}{}
Sánchez-Meca, J., \& Marín-Martínez, F. (2008). Confidence intervals for
the overall effect size in random-effects meta-analysis.
\emph{Psychological Methods}, \emph{13}(1), 31--48.
doi:\href{https://doi.org/10.1037/1082-989X.13.1.31}{10.1037/1082-989X.13.1.31}

\hypertarget{ref-Scheff1979}{}
Scheff, T. J. (1979). \emph{Catharsis in healing, ritual, and drama}.
Los Angeles: University of California Press.

\hypertarget{ref-Simonsohn2014}{}
Simonsohn, U., Nelson, L. D., \& Simmons, J. P. (2014). p-curve: A key
to the file-drawer. \emph{Journal of Experimental Psychology: General},
\emph{143}(2), 534--547.
doi:\href{https://doi.org/10.1037/a0033242}{10.1037/a0033242}

\hypertarget{ref-Simonsohn2015}{}
Simonsohn, U., Simmons, J. P., \& Nelson, L. D. (2015). Better p-curves:
Making p-curve analysis more robust to errors, fraud, and ambitious
p-hacking, a reply to Ulrich and Miller (2015). \emph{Journal of
Experimental Psychology: General}, \emph{144}(6), 1146--1152.
doi:\href{https://doi.org/10.1037/xge0000104}{10.1037/xge0000104}

\hypertarget{ref-Slavin-Spenny2011}{}
Slavin-Spenny, O. M., Cohen, J. L., Oberleitner, L. M., \& Lumley, M. A.
(2011). The effects of different methods of emotional disclosure:
Differentiating posttraumatic growth from stress symptoms. \emph{Journal
of Clinical Psychology}, \emph{67}(10), 993--1007.
doi:\href{https://doi.org/10.1002/jclp.20750}{10.1002/jclp.20750}

\hypertarget{ref-Sloan2011a}{}
Sloan, D. M., Marx, B. P., \& Greenberg, E. M. (2011). A test of written
emotional disclosure as an intervention for posttraumatic stress
disorder. \emph{Behaviour Research and Therapy}, \emph{49}(4), 299--304.
doi:\href{https://doi.org/10.1016/j.brat.2011.02.001}{10.1016/j.brat.2011.02.001}

\hypertarget{ref-Sloan2012}{}
Sloan, D. M., Marx, B. P., Bovin, M. J., Feinstein, B. A., \& Gallagher,
M. W. (2012). Written exposure as an intervention for PTSD: A randomized
clinical trial with motor vehicle accident survivors. \emph{Behaviour
Research and Therapy}, \emph{50}(10), 627--635.
doi:\href{https://doi.org/10.1016/j.brat.2012.07.001}{10.1016/j.brat.2012.07.001}

\hypertarget{ref-Sloan2007}{}
Sloan, D. M., Marx, B. P., Epstein, E. M., \& Lexington, J. M. (2007).
Does altering the writing instructions influence outcome associated with
written disclosure? \emph{Behavior Therapy}, \emph{38}(2), 155--168.
doi:\href{https://doi.org/10.1016/j.beth.2006.06.005}{10.1016/j.beth.2006.06.005}

\hypertarget{ref-Sloan2018}{}
Sloan, D. M., Marx, B. P., Lee, D. J., \& Resick, P. A. (2018). A brief
exposure-based treatment vs cognitive processing therapy for
Posttraumatic Stress Disorder. \emph{JAMA Psychiatry}.
doi:\href{https://doi.org/10.1001/jamapsychiatry.2017.4249}{10.1001/jamapsychiatry.2017.4249}

\hypertarget{ref-Smithson2001}{}
Smithson, M. (2001). Correct confidence intervals for various regression
effect sizes and parameters: The importance of noncentral distributions
in computing intervals. \emph{Educational and Psychological
Measurement}, \emph{61}(4), 605--632.
doi:\href{https://doi.org/10.1177/00131640121971392}{10.1177/00131640121971392}

\hypertarget{ref-Smithson2003}{}
Smithson, M. (2003). \emph{Confidence intervals}. Thousand Oaks, CA:
Sage.

\hypertarget{ref-Smyth1998}{}
Smyth, J. M. (1998). Written emotional expression: Effect sizes ,
outcome types, and moderating variables. \emph{Journal of Consulting and
Clinical Psychology}, \emph{66}(1), 174--184.
doi:\href{https://doi.org/10.1037/0022-006X.66.1.174}{10.1037/0022-006X.66.1.174}

\hypertarget{ref-Smyth1999}{}
Smyth, J. M., Stone, A. A., Hurewitz, A., \& Kaell, A. (1999). Effects
of writing about stressful experiences on symptom reduction in patients
with asthma or rheumatoid arthritis: A randomized trial. \emph{JAMA: The
Journal of the American Medical Association}, \emph{281}(14),
1304--1309.
doi:\href{https://doi.org/10.1001/jama.281.14.1304}{10.1001/jama.281.14.1304}

\hypertarget{ref-Stanley2005}{}
Stanley, T. D. (2005). Beyond publication bias. \emph{Journal of
Economic Surveys}, \emph{19}(3), 309--345.
doi:\href{https://doi.org/10.1111/j.0950-0804.2005.00250.x}{10.1111/j.0950-0804.2005.00250.x}

\hypertarget{ref-Stanley2014}{}
Stanley, T. D., \& Doucouliagos, H. (2014). Meta-regression
approximations to reduce publication selection bias. \emph{Research
Synthesis Methods}, \emph{5}(1), 60--78.
doi:\href{https://doi.org/10.1002/jrsm.1095}{10.1002/jrsm.1095}

\hypertarget{ref-Stanton2002}{}
Stanton, A. L., Danoff-Burg, S., Sworowski, L. A., Collins, C. A.,
Branstetter, A. D., Rodriguez-Hanley, A., \ldots{} Austenfeld, J. L.
(2002). Randomized, controlled trial of written emotional expression and
benefit finding in breast cancer patients. \emph{Journal of Clinical
Oncology}, \emph{20}(20), 4160--4168.
doi:\href{https://doi.org/10.1200/JCO.2002.08.521}{10.1200/JCO.2002.08.521}

\hypertarget{ref-Taku2008}{}
Taku, K., Calhoun, L. G., Cann, A., \& Tedeschi, R. G. (2008). The role
of rumination in the coexistence of distress and posttraumatic growth
among bereaved Japanese University students. \emph{Death Studies},
\emph{32}(5), 428--444.
doi:\href{https://doi.org/10.1080/07481180801974745}{10.1080/07481180801974745}

\hypertarget{ref-Tedeschi1995}{}
Tedeschi, R. G., \& Calhoun, L. G. (1995). \emph{Trauma \&
transformation: Growing in the aftermath of suffering.} Thousand Oaks,
CA: Sage Publications.

\hypertarget{ref-Tedeschi2004}{}
Tedeschi, R. G., \& Calhoun, L. G. (2004). Posttraumatic growth:
Conceptual foundations and empirical evidence. \emph{Psychological
Inquiry}, \emph{15}(1), 1--18.
doi:\href{https://doi.org/10.1207/s15327965pli1501}{10.1207/s15327965pli1501}

\hypertarget{ref-Terrin2003}{}
Terrin, N., Schmid, C. H., Lau, J., \& Olkin, I. (2003). Adjusting for
publication bias in the presence of heterogeneity. \emph{Statistics in
Medicine}, \emph{22}(13), 2113--2126.
doi:\href{https://doi.org/10.1002/sim.1461}{10.1002/sim.1461}

\hypertarget{ref-Theofilou2013}{}
Theofilou, P. (2013). Quality of life: Definition and measurement.
\emph{Europe's Journal of Psychology}, \emph{9}(1), 150--162.
doi:\href{https://doi.org/10.5964/ejop.v9i1.337}{10.5964/ejop.v9i1.337}

\hypertarget{ref-VanAert2017}{}
Van Aert, R. C. M. (2017). P-uniform. GitHub. Retrieved from
\url{https://github.com/RobbievanAert/puniform}

\hypertarget{ref-VanAert2016}{}
Van Aert, R. C. M., Wicherts, J. M., \& Van Assen, M. A. L. M. (2016).
Conducting meta-analyses based on p-values: Reservations and
recommendations for applying p-uniform and p-curve. \emph{Perspectives
on Psychological Science}, \emph{11}(5), 713--729.
doi:\href{https://doi.org/10.1017/CBO9781107415324.004}{10.1017/CBO9781107415324.004}

\hypertarget{ref-VanAssen2015}{}
Van Assen, M. A. L. M., Van Aert, R. C. M., \& Wicherts, J. M. (2015).
Meta-analysis using effect size distributions of only statistically
significant studies. \emph{Psychological Methods}, \emph{20}(3),
293--309.
doi:\href{https://doi.org/http://dx.doi.org/10.1037/met0000025}{http://dx.doi.org/10.1037/met0000025}

\hypertarget{ref-VanElk2015}{}
Van Elk, M., Matzke, D., Gronau, Q. F., Guan, M., Vandekerckhove, J., \&
Wagenmakers, E.-J. (2015). Meta-analyses are no substitute for
registered replications: A skeptical perspective on religious priming.
\emph{Frontiers in Psychology}, \emph{6}, 1365.
doi:\href{https://doi.org/10.3389/fpsyg.2015.01365}{10.3389/fpsyg.2015.01365}

\hypertarget{ref-VanEmmerik2013}{}
Van Emmerik, A. A. P., Reijntjes, A., \& Kamphuis, J. H. (2013). Writing
therapy for posttraumatic stress: A meta-analysis. \emph{Psychotherapy
and Psychosomatics}, \emph{82}(2), 82--88.
doi:\href{https://doi.org/10.1159/000343131}{10.1159/000343131}

\hypertarget{ref-Vevea1995}{}
Vevea, J. L., \& Hedges, L. V. (1995). A general linear model for
estimating effect size in the presence of publication bias.
\emph{Psychometrika}, \emph{60}(3), 419--435.
doi:\href{https://doi.org/10.1007/BF02294384}{10.1007/BF02294384}

\hypertarget{ref-Vevea2005}{}
Vevea, J. L., \& Woods, C. M. (2005). Publication bias in research
synthesis: Sensitivity analysis using a priori weight functions.
\emph{Psychological Methods}, \emph{10}(4), 428--443.
doi:\href{https://doi.org/10.1037/1082-989X.10.4.428}{10.1037/1082-989X.10.4.428}

\hypertarget{ref-Viechtbauer2010}{}
Viechtbauer, W. (2010). Conducting meta-analyses in R with the metafor
package. \emph{Journal of Statistical Software}, \emph{36}(3), 1--48.
doi:\href{https://doi.org/10.18637/jss.v036.i03}{10.18637/jss.v036.i03}

\hypertarget{ref-Wang2000}{}
Wang, X., Gao, L., Shinfuku, N., Zhang, H., Zhao, C., \& Shen, Y.
(2000). Longitudinal study of earthquake-related PTSD in a randomly
selected community sample in North China. \emph{American Journal of
Psychiatry}, \emph{157}(8), 1260--1266.
doi:\href{https://doi.org/10.1176/appi.ajp.157.8.1260}{10.1176/appi.ajp.157.8.1260}

\hypertarget{ref-Weiss2002}{}
Weiss, T. (2002). Posttraumatic growth in women with breast cancer and
their husbands -- An intersubjective validation study. \emph{Journal of
Psychosocial Oncology}, \emph{20}(2), 65--80.
doi:\href{https://doi.org/10.1300/J077v20n02_04}{10.1300/J077v20n02\_04}

\hypertarget{ref-Yilmaz2016}{}
Yilmaz, M., \& Zara, A. (2016). Traumatic loss and posttraumatic growth:
The effect of traumatic loss related factors on posttraumatic growth.
\emph{Anatolian Journal of Psychiatry}, \emph{17}(1), 5--11.
doi:\href{https://doi.org/10.5455/apd.188311}{10.5455/apd.188311}






\end{document}
